{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HKCN-6C1ejO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# YAML config\n",
    "try:\n",
    "    with open(r\".\\config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "# Logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(funcName)s - %(message)s\",\n",
    "    filename=config[\"log_dir\"] +\n",
    "    f\"{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}.log\",\n",
    "    filemode=\"w\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Config file and logger setup completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv(config[\"data_path\"])\n",
    "    logger.info(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    logger.error(\"Error: CSV file not found.  Please check the file path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration\n",
    "df = df.set_index(\"car_ID\")\n",
    "\n",
    "logger.info(\"Initial DataFrame shape: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Missing Values\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"Missing values found. Imputation will be performed.\")\n",
    "    logger.warning(\"Missing values found. Imputation will be performed.\")\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "    logger.info(\"No missing values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Inspection\n",
    "df.info()\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df[\"brand\"] = df[\"CarName\"].str.split(\" \", n=1, expand=True)[0]\n",
    "df[\"model\"] = df[\"CarName\"].str.split(\" \", n=1, expand=True)[\n",
    "    1].str.replace(\" \", \"\")\n",
    "\n",
    "df = df.drop(\"CarName\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring columns\n",
    "numeric_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(\n",
    "    df[col]) and col != \"price\"]\n",
    "categorical_cols = [\n",
    "    col for col in df.columns if col not in numeric_cols and col != \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(np.abs(stats.zscore(df[numeric_cols])) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "logger.info(\"Applying One-Hot Encoding...\")\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "preprocessor = ColumnTransformer(\n",
    "    [(\"onehot\", encoder, categorical_cols)], remainder=\"passthrough\")\n",
    "df_processed = pd.DataFrame(preprocessor.fit_transform(\n",
    "    df), columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [column for column in list(\n",
    "    df_processed.columns) if not column.startswith(\"onehot\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Numeric Features\n",
    "scaler = StandardScaler()\n",
    "df_processed[numeric_cols] = scaler.fit_transform(df_processed[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X = df_processed\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"R2 Score: {r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "pickle.dump(model, open(config[\"save_model_name\"], \"wb\"))\n",
    "logger.info(f\"Model saved to {config[\"save_model_name\"]}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMW3OX7jjMk2Zt+pYR5wDrJ",
   "mount_file_id": "15XyHsFOsrkx_a9Xw9hpnnw1Wkr3Pa6zK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
